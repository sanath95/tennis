{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN NEXT 2 CELLS TO OBTAIN IMGS FOR TRAINING AND TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "backhand_path=r'E:\\opencv\\tennis2\\train\\backhand'\n",
    "backhand_vids=os.listdir(backhand_path)\n",
    "\n",
    "for vid in backhand_vids:\n",
    "\n",
    "    vid_name=vid.split('.')[0]\n",
    "    #print(vid_name)\n",
    "    cap = cv2.VideoCapture(os.path.join(backhand_path,vid))\n",
    "    count=0\n",
    "    while(True):\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if ret==False:\n",
    "            break\n",
    "        file_name_path = backhand_path + '\\\\' +str(count)+'-'+ str(vid_name) + '.jpg'\n",
    "        frame_gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imwrite(file_name_path, frame_gray)  \n",
    "        count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "forehand_path=r'E:\\opencv\\tennis2\\train\\forehand'\n",
    "forehand_vids=os.listdir(forehand_path)\n",
    "\n",
    "for vid in forehand_vids:\n",
    "\n",
    "    vid_name=vid.split('.')[0]\n",
    "    #print(vid_name)\n",
    "    cap = cv2.VideoCapture(os.path.join(forehand_path,vid))\n",
    "    count=0\n",
    "    while(True):\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if ret==False:\n",
    "            break\n",
    "        file_name_path = forehand_path + '\\\\' +str(count)+'-'+ str(vid_name) + '.jpg'\n",
    "        frame_gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imwrite(file_name_path, frame_gray)  \n",
    "        count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63065 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1.0/255.0,horizontal_flip=True)\n",
    "training_set=train_datagen.flow_from_directory(r'E:\\opencv\\tennis2\\train',target_size=(64,64),batch_size=32,class_mode='binary',color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31465 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_set=test_datagen.flow_from_directory(r'E:\\opencv\\tennis2\\test',target_size=(64,64),batch_size=32,class_mode='binary',color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=tf.keras.models.Sequential()\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu',input_shape=(64,64,1)))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=256,activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1971/1971 [==============================] - 2128s 1s/step - loss: 0.4406 - accuracy: 0.7638 - val_loss: 0.2298 - val_accuracy: 0.9082\n",
      "Epoch 2/10\n",
      "1971/1971 [==============================] - 1656s 840ms/step - loss: 0.1498 - accuracy: 0.9404 - val_loss: 0.1429 - val_accuracy: 0.9439\n",
      "Epoch 3/10\n",
      "1971/1971 [==============================] - 1604s 814ms/step - loss: 0.0871 - accuracy: 0.9668 - val_loss: 0.1389 - val_accuracy: 0.9539\n",
      "Epoch 4/10\n",
      "1971/1971 [==============================] - 1644s 834ms/step - loss: 0.0630 - accuracy: 0.9771 - val_loss: 0.1383 - val_accuracy: 0.9544\n",
      "Epoch 5/10\n",
      "1971/1971 [==============================] - 1648s 836ms/step - loss: 0.0468 - accuracy: 0.9831 - val_loss: 0.1367 - val_accuracy: 0.9539\n",
      "Epoch 6/10\n",
      "1971/1971 [==============================] - 1608s 816ms/step - loss: 0.0385 - accuracy: 0.9867 - val_loss: 0.1307 - val_accuracy: 0.9609\n",
      "Epoch 7/10\n",
      "1971/1971 [==============================] - 1611s 817ms/step - loss: 0.0347 - accuracy: 0.9877 - val_loss: 0.1461 - val_accuracy: 0.9602\n",
      "Epoch 8/10\n",
      "1971/1971 [==============================] - 1612s 818ms/step - loss: 0.0293 - accuracy: 0.9896 - val_loss: 0.1405 - val_accuracy: 0.9596\n",
      "Epoch 9/10\n",
      "1971/1971 [==============================] - 1677s 851ms/step - loss: 0.0277 - accuracy: 0.9902 - val_loss: 0.1235 - val_accuracy: 0.9659\n",
      "Epoch 10/10\n",
      "1971/1971 [==============================] - 1630s 827ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 0.1243 - val_accuracy: 0.9693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x8cce160>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checkpoint=ModelCheckpoint('tennis-{epoch:02d}.model',monitor='val_accuracy',verbose=0,save_best_only=True,mode='auto')\n",
    "\n",
    "cnn.fit(x=training_set,validation_data=test_set,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save(\"tennis-grayscale-softmax-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('tennis-grayscale-softmax-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'backhand': 0, 'forehand': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backhand-1 Forehand\n",
      "backhand-10 Forehand\n",
      "backhand-2 Forehand\n",
      "backhand-3 Forehand\n",
      "backhand-4 Forehand\n",
      "backhand-5 Forehand\n",
      "backhand-6 Forehand\n",
      "backhand-7 Forehand\n",
      "backhand-8 Forehand\n",
      "backhand-9 Forehand\n",
      "forehand-1 Forehand\n",
      "forehand-10 Forehand\n",
      "forehand-2 Forehand\n",
      "forehand-3 Forehand\n",
      "forehand-4 Forehand\n",
      "forehand-5 Forehand\n",
      "forehand-6 Forehand\n",
      "forehand-7 Forehand\n",
      "forehand-8 Forehand\n",
      "forehand-9 Forehand\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "path=\"E:\\\\opencv\\\\tennis2\\\\validation\\\\\"\n",
    "img_names=os.listdir(path)\n",
    "for img in img_names:\n",
    "    test_image=image.load_img(os.path.join(path,img),target_size=(64,64))\n",
    "    test_img=cv2.cvtColor(np.float32(test_image), cv2.COLOR_BGR2GRAY)\n",
    "    test_img=image.img_to_array(test_img)\n",
    "    test_img=np.expand_dims(test_img,axis=0)\n",
    "    result=cnn.predict(test_img)\n",
    "    if result[0][0]==0:\n",
    "        x='Backhand'\n",
    "    else:\n",
    "        x='Forehand'\n",
    "    print(img.split('.')[0]+'-'+img.split('.')[1],x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backhand-1 Backhand\n",
      "backhand-10 Backhand\n",
      "backhand-2 Forehand\n",
      "backhand-3 Forehand\n",
      "backhand-4 Forehand\n",
      "backhand-5 Backhand\n",
      "backhand-6 Backhand\n",
      "backhand-7 Backhand\n",
      "backhand-8 Forehand\n",
      "backhand-9 Forehand\n",
      "forehand-1 Forehand\n",
      "forehand-10 Backhand\n",
      "forehand-2 Forehand\n",
      "forehand-3 Forehand\n",
      "forehand-4 Forehand\n",
      "forehand-5 Backhand\n",
      "forehand-6 Backhand\n",
      "forehand-7 Forehand\n",
      "forehand-8 Backhand\n",
      "forehand-9 Forehand\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "path=\"E:\\\\opencv\\\\tennis2\\\\validation\\\\\"\n",
    "img_names=os.listdir(path)\n",
    "for img in img_names:\n",
    "    test_image=image.load_img(os.path.join(path,img),target_size=(64,64))\n",
    "    #test_img=cv2.cvtColor(np.float32(test_image), cv2.COLOR_BGR2GRAY)\n",
    "    test_img=image.img_to_array(test_image)\n",
    "    test_img=np.expand_dims(test_img,axis=0)\n",
    "    result=model.predict(test_img)\n",
    "    if result[0][0]==0:\n",
    "        x='Backhand'\n",
    "    else:\n",
    "        x='Forehand'\n",
    "    print(img.split('.')[0]+'-'+img.split('.')[1],x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
